{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Color quantization k-means\n",
    "\n",
    "For this problem you will write code to quantize a color space by applying k-means clustering to the pixels in a given input image. We will experiment with two different color spaces — RGB and HSV.\n",
    "\n",
    "Implement each of the specified functions in the `quantization_student.py`. After each function there is a test on the 4x6 image that will be generated within this notebook. These test are to help you verify and debug your code. However, they will not cover every possible edge case. We encourage you to write additional test or debug your code line-by-line to make sure the functions work as expected.\n",
    "\n",
    "> Note: to pass the tests in this notebook and on Gradescope you will need to use a random seed value of `101` whenever possible. Please check the docstrings for any of the 3rd party functions to make sure you set the random seed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#export\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from quantization_student import quantizeRGB, quantizeHSV, computeQuantizationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands in the following cell will plot all images/plots in an interactive window. If you would prefer to not have interactive plots, comment out %matplotlib notebook and uncomment %matplotlib inline instead.\n",
    "\n",
    "You can use plt.rcParams['figure.figsize'] to make all the plots in this notebook bigger or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_k = 4\n",
    "np.random.seed(101)\n",
    "test_img = np.random.randint(0, 256, size=(4, 6, 3), dtype=np.uint8)\n",
    "_, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Quantize in RGB space\n",
    "\n",
    "Given an RGB image, quantize the 3-dimensional RGB space, and map each pixel in the input image to its nearest k-means center. That is, replace the RGB value at each pixel with its nearest cluster’s average RGB value.\n",
    "\n",
    "Use the [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class to perfom the k-means clustering. See the documentation for details on how to use the class, and make sure you set `random_state=101`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_quantized_img_rgb = np.array([[[159, 173,  49],\n",
    "        [ 80,  34,  60],\n",
    "        [159, 173,  49],\n",
    "        [ 99,  60, 190],\n",
    "        [ 99,  60, 190],\n",
    "        [159, 173,  49]],\n",
    "\n",
    "       [[ 80,  34,  60],\n",
    "        [ 99,  60, 190],\n",
    "        [209, 185, 212],\n",
    "        [ 80,  34,  60],\n",
    "        [ 99,  60, 190],\n",
    "        [ 99,  60, 190]],\n",
    "\n",
    "       [[ 99,  60, 190],\n",
    "        [159, 173,  49],\n",
    "        [159, 173,  49],\n",
    "        [ 80,  34,  60],\n",
    "        [ 99,  60, 190],\n",
    "        [ 99,  60, 190]],\n",
    "\n",
    "       [[209, 185, 212],\n",
    "        [209, 185, 212],\n",
    "        [159, 173,  49],\n",
    "        [ 80,  34,  60],\n",
    "        [209, 185, 212],\n",
    "        [ 99,  60, 190]]], dtype=np.uint8)\n",
    "\n",
    "quantized_img_rgb, _ = quantizeRGB(test_img, test_k)\n",
    "\n",
    "if np.allclose(quantized_img_rgb, expected_quantized_img_rgb):\n",
    "    print(\"\\nQuantized image computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nQuantized image is incorrect.\")\n",
    "    print(f\"\\nexpected:\\n\\n{expected_quantized_img_rgb}\")\n",
    "    print(f\"\\ncomputed:\\n\\n{quantized_img_rgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].imshow(test_img)\n",
    "\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].imshow(quantized_img_rgb)\n",
    "\n",
    "# uncomment this line and change the filename as needed to save the figure\n",
    "# fig.savefig(f\"output-quantized-rgb-{k}.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Quantize in HSV space\n",
    "\n",
    "Given an RGB image, convert it to HSV and quantize the 1-dimensional Hue space. Map each pixel in the input image to its nearest quantized Hue value, while keeping its Saturation and Value channels the same as the input. Convert the quantized output back to RGB color space.\n",
    "\n",
    "Use the [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class to perfom the k-means clustering. See the documentation for details on how to use the class, and make sure you set `random_state=101`.\n",
    "\n",
    "Use the [skimage.color.rgb2hsv](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.rgb2hsv) and [skimage.color.hsv2rgb](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.hsv2rgb) functions to convert the image to HSV and back to RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_quantized_img_hsv = np.array([[[ 94, 179,  49],\n",
    "        [131,  11, 112],\n",
    "        [101, 141,  81],\n",
    "        [ 38,  23, 146],\n",
    "        [ 55,  31, 227],\n",
    "        [243, 166,  22]],\n",
    "\n",
    "       [[ 87,   7,  74],\n",
    "        [252,   3, 212],\n",
    "        [253, 215, 246],\n",
    "        [ 54,  75,  43],\n",
    "        [ 29,   0, 239],\n",
    "        [ 90,  79, 175]],\n",
    "\n",
    "       [[132, 125, 187],\n",
    "        [114, 205,  66],\n",
    "        [ 99, 213,  40],\n",
    "        [ 86,  17,  75],\n",
    "        [149,  86, 139],\n",
    "        [ 72,  63, 138]],\n",
    "\n",
    "       [[192, 147, 184],\n",
    "        [199, 195, 227],\n",
    "        [245, 172,  36],\n",
    "        [ 68,  53,  24],\n",
    "        [187, 183, 220],\n",
    "        [ 68,  49, 199]]], dtype=np.uint8)\n",
    "\n",
    "quantized_img_hsv, _ = quantizeHSV(test_img, test_k)\n",
    "\n",
    "if np.allclose(quantized_img_hsv, expected_quantized_img_hsv):\n",
    "    print(\"\\nQuantized image computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nQuantized image is incorrect.\")\n",
    "    print(f\"\\nexpected:\\n\\n{expected_quantized_img_hsv}\")\n",
    "    print(f\"\\ncomputed:\\n\\n{quantized_img_hsv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].imshow(test_img)\n",
    "\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].imshow(quantized_img_hsv)\n",
    "\n",
    "# uncomment this line and change the filename as needed to save the figure\n",
    "# fig.savefig(f\"output-quantized-hsv-{k}.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Sum of squared error\n",
    "\n",
    "Write a function to compute the SSD error (sum of squared error) between the original RGB pixel values and the quantized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rgb = computeQuantizationError(test_img, quantized_img_rgb)\n",
    "print(f\"quantization error (rgb): {error_rgb:,}\")\n",
    "\n",
    "error_hsv = computeQuantizationError(test_img, quantized_img_hsv)\n",
    "print(f\"quantization error (hsv): {error_hsv:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if error_rgb == 112251:\n",
    "    print(\"\\nQuantization error computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nQuantization error incorrect\")\n",
    "    print(f\"\\nexpected: 112,251\\ncomputed: {error_rgb}\")\n",
    "\n",
    "\n",
    "if error_hsv == 33167:\n",
    "    print(\"\\nQuantization error computed correctly!\")\n",
    "else:\n",
    "    print(\"\\nQuantization error incorrect\")\n",
    "    print(f\"\\nexpected: 33,167\\ncomputed: {error_hsv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the outputs when quantization is performed on real images. Make sure to include results from this part in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('data/fish.jpg')\n",
    "im = np.asarray(im, dtype = np.uint8)\n",
    "im.shape\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quantization(im: np.ndarray, n_k: int, color_space: str ='RGB') -> None:\n",
    "    \"\"\"Performs color quantization on the input image for all \n",
    "    the input number of clusters, assuming the input colorspace.\n",
    "\n",
    "    Args:\n",
    "        im: Input image, assumed to be an ndarray.\n",
    "        n_k: list of cluster centers to perform quantization on.\n",
    "        color_space: used to decide which function to call.\n",
    "\n",
    "    Returns:\n",
    "        quantized_imgs: list of quantized images\n",
    "        cluster_centers: list of cluster centers of the generated \n",
    "                         clusters at each k. \n",
    "        quantization_errors: computed quantization error between \n",
    "                             the generated image and original image.\n",
    "    \"\"\"\n",
    "    quantized_imgs = []\n",
    "    cluster_centers = []\n",
    "    quantization_errors = []\n",
    "    \n",
    "    for k in n_k:\n",
    "        if(color_space == 'RGB' or color_space == 'rgb'):\n",
    "            quantized_img, cluster_center = quantizeRGB(im, k)\n",
    "        elif(color_space == 'HSV' or color_space == 'hsv'):\n",
    "            quantized_img, cluster_center = quantizeHSV(im, k)\n",
    "        else:\n",
    "            print(\"Error: Enter either \\'RGB\\' or \\'HSV\\' as a colorspace\")\n",
    "            return\n",
    "            \n",
    "        quantized_imgs.append(quantized_img)\n",
    "        cluster_centers.append(cluster_center)\n",
    "        quantization_errors.append(\n",
    "            np.log(computeQuantizationError(im, quantized_img))\n",
    "        )\n",
    "    \n",
    "    nrows = int(np.ceil(len(n_k)/2))\n",
    "    ncols = 2\n",
    "    fig,axes = plt.subplots(nrows = nrows, ncols = ncols, figsize=(nrows*10,20))\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, k in enumerate(n_k):\n",
    "        title = 'K = '+str(k)+\", err = e^(\"+str(quantization_errors[i]) + \")\"\n",
    "        \n",
    "        if(nrows > 1):\n",
    "            axes[i//ncols, i%ncols].imshow(np.asarray(quantized_imgs[i], dtype=int))\n",
    "            axes[i//ncols, i%ncols].set_title(title)\n",
    "        else:\n",
    "            axes[i].imshow(np.asarray(quantized_imgs[i], dtype=int))\n",
    "            axes[i].set_title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_quantization(im, n_k = [3, 5, 10], color_space='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_quantization(im, n_k = [3, 5, 10], color_space='HSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hough Transform\n",
    "\n",
    "The Hough transform is a feature extraction technique used in image analysis, computer vision, and digital image processing. The purpose of the technique is to find imperfect instances of objects within a certain class of shapes by a voting procedure. This voting procedure is carried out in a parameter space, from which object candidates are obtained as local maxima in a so-called accumulator space that is explicitly constructed by the algorithm for computing the Hough transform.\n",
    "\n",
    "![alt text](ideal.jfif \"Title\")\n",
    "\n",
    "Source: Wikipedia \n",
    "Image source: Google Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem you will be implementing a Hough Transform based circle detector that takes an input image and a fixed radius,\n",
    "and returns the centers and radii of any detected circles of about that size and the Hough space used\n",
    "for finding the centers. Implement the `detectCircles()` function in `detect_circles_student.py`. \n",
    "\n",
    "We will use some tests to verify your implementation. These tests are to help you verify and debug your code. However, they will not cover every possible edge case. We encourage you to write additional test or debug your code line-by-line to make sure the functions work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detect_circles_student import detectCircles, showCircles\n",
    "from test_simple import PS04Test\n",
    "Checker = PS04Test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Circle Detection\n",
    "\n",
    "Running basic tests on your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Checker.testDetectCircles(detectCircles, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Checker.testDetectCircles(detectCircles, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_syn = Image.open(\"data/im1.jpg\")\n",
    "im_syn = np.asarray(im_syn, dtype = np.uint8)\n",
    "im_syn.shape\n",
    "plt.imshow(im_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_real = Image.open(\"data/biliards.jpg\")\n",
    "im_real = np.asarray(im_real, dtype = np.uint8)\n",
    "im_real.shape\n",
    "plt.imshow(im_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in 2.2 and 2.3, visualize the detected circles for the above images and include them in your report. You may use the `showCircles()` function."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}